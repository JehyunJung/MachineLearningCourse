{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Projects\\\\MLDL\\\\Ensemble'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재경로 확인\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0   1       1       0       0       0       0       0       0       0       0   \n",
       "1   2       0       0       0       0       0       0       0       1       0   \n",
       "2   3       0       0       0       0       0       0       0       1       0   \n",
       "3   4       1       0       0       1       6       1       5       0       0   \n",
       "4   5       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  feat_91  \\\n",
       "0  ...        1        0        0        0        0        0        0   \n",
       "1  ...        0        0        0        0        0        0        0   \n",
       "2  ...        0        0        0        0        0        0        0   \n",
       "3  ...        0        1        2        0        0        0        0   \n",
       "4  ...        1        0        0        0        0        1        0   \n",
       "\n",
       "   feat_92  feat_93   target  \n",
       "0        0        0  Class_1  \n",
       "1        0        0  Class_1  \n",
       "2        0        0  Class_1  \n",
       "3        0        0  Class_1  \n",
       "4        0        0  Class_1  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "data = pd.read_csv(\"./otto_train.csv\") # Product Category\n",
    "data.head() # 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nid: 고유 아이디\\nfeat_1 ~ feat_93: 설명변수\\ntarget: 타겟변수 (1~9)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "id: 고유 아이디\n",
    "feat_1 ~ feat_93: 설명변수\n",
    "target: 타겟변수 (1~9)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nCar: 61878 nVar: 95\n"
     ]
    }
   ],
   "source": [
    "nCar = data.shape[0] # 데이터 개수\n",
    "nVar = data.shape[1] # 변수 개수\n",
    "print('nCar: %d' % nCar, 'nVar: %d' % nVar )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 의미가 없다고 판단되는 변수 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['id'], axis = 1) # id 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 타겟 변수의 문자열을 숫자로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {\"Class_1\": 1,\n",
    "                \"Class_2\": 2,\n",
    "                \"Class_3\": 3,\n",
    "                \"Class_4\": 4,\n",
    "                \"Class_5\": 5,\n",
    "                \"Class_6\": 6,\n",
    "                \"Class_7\": 7,\n",
    "                \"Class_8\": 8,\n",
    "                \"Class_9\": 9}\n",
    "after_mapping_target = data['target'].apply(lambda x: mapping_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설명변수와 타겟변수를 분리, 학습데이터와 평가데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49502, 93) (12376, 93) (49502,) (12376,)\n"
     ]
    }
   ],
   "source": [
    "feature_columns = list(data.columns.difference(['target'])) # target을 제외한 모든 행\n",
    "X = data[feature_columns] # 설명변수\n",
    "y = after_mapping_target # 타겟변수\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2, random_state = 42) # 학습데이터와 평가데이터의 비율을 8:2 로 분할| \n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape) # 데이터 개수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-1.0.2-py3-none-win_amd64.whl (24.6 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\jhyun\\anaconda3\\lib\\site-packages (from xgboost) (1.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\jhyun\\anaconda3\\lib\\site-packages (from xgboost) (1.16.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:30:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.0.0\\src\\learner.cc:328: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Accuracy: 76.67 %\n",
      "Time: 18.13 seconds\n"
     ]
    }
   ],
   "source": [
    "# !pip install xgboost\n",
    "import xgboost as xgb\n",
    "import time\n",
    "start = time.time() # 시작 시간 지정\n",
    "xgb_dtrain = xgb.DMatrix(data = train_x, label = train_y) # 학습 데이터를 XGBoost 모델에 맞게 변환\n",
    "xgb_dtest = xgb.DMatrix(data = test_x) # 평가 데이터를 XGBoost 모델에 맞게 변환\n",
    "xgb_param = {'max_depth': 10, # 트리 깊이\n",
    "         'learning_rate': 0.01, # Step Size\n",
    "         'n_estimators': 100, # Number of trees, 트리 생성 개수\n",
    "         'objective': 'multi:softmax', # 목적 함수\n",
    "        'num_class': len(set(train_y)) + 1} # 파라미터 추가, Label must be in [0, num_class) -> num_class보다 1 커야한다.\n",
    "xgb_model = xgb.train(params = xgb_param, dtrain = xgb_dtrain) # 학습 진행\n",
    "xgb_model_predict = xgb_model.predict(xgb_dtest) # 평가 데이터 예측\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(test_y, xgb_model_predict) * 100), \"%\") # 정확도 % 계산\n",
    "print(\"Time: %.2f\" % (time.time() - start), \"seconds\") # 코드 실행 시간 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 3., 6., ..., 9., 2., 7.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Using cached lightgbm-2.3.1-py2.py3-none-win_amd64.whl (544 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jhyun\\anaconda3\\lib\\site-packages (from lightgbm) (0.21.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\jhyun\\anaconda3\\lib\\site-packages (from lightgbm) (1.16.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\jhyun\\anaconda3\\lib\\site-packages (from lightgbm) (1.3.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\jhyun\\anaconda3\\lib\\site-packages (from scikit-learn->lightgbm) (0.13.2)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.61 %\n",
      "Time: 12.71 seconds\n"
     ]
    }
   ],
   "source": [
    "# !pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "start = time.time() # 시작 시간 지정\n",
    "lgb_dtrain = lgb.Dataset(data = train_x, label = train_y) # 학습 데이터를 LightGBM 모델에 맞게 변환\n",
    "lgb_param = {'max_depth': 30, # 트리 깊이\n",
    "            'learning_rate': 0.01, # Step Size\n",
    "            'n_estimators': 100, # Number of trees, 트리 생성 개수\n",
    "            'objective': 'multiclass', # 목적 함수\n",
    "            'num_class': len(set(train_y)) + 1} # 파라미터 추가, Label must be in [0, num_class) -> num_class보다 1 커야한다.\n",
    "lgb_model = lgb.train(params = lgb_param, train_set = lgb_dtrain) # 학습 진행\n",
    "lgb_model_predict = np.argmax(lgb_model.predict(test_x), axis = 1) # 평가 데이터 예측, Softmax의 결과값 중 가장 큰 값의 Label로 예측\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(test_y, lgb_model_predict) * 100), \"%\") # 정확도 % 계산\n",
    "print(\"Time: %.2f\" % (time.time() - start), \"seconds\") # 코드 실행 시간 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data=lgb_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12376"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Using cached catboost-0.22-cp37-none-win_amd64.whl (63.4 MB)\n",
      "Requirement already satisfied: graphviz in c:\\users\\jhyun\\anaconda3\\lib\\site-packages (from catboost) (0.13.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jhyun\\anaconda3\\lib\\site-packages (from catboost) (3.1.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\jhyun\\anaconda3\\lib\\site-packages (from catboost) (1.3.1)\n",
      "Collecting plotly\n",
      "  Using cached plotly-4.5.3-py2.py3-none-any.whl (7.1 MB)\n",
      "Requirement already satisfied: six in c:\\users\\jhyun\\anaconda3\\lib\\site-packages (from catboost) (1.12.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\jhyun\\anaconda3\\lib\\site-packages (from catboost) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\jhyun\\anaconda3\\lib\\site-packages (from catboost) (1.16.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jhyun\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jhyun\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\jhyun\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\jhyun\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (2.8.0)\n",
      "Processing c:\\users\\jhyun\\appdata\\local\\pip\\cache\\wheels\\f9\\8d\\8d\\f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\\retrying-1.3.3-py3-none-any.whl\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\jhyun\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2019.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jhyun\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (41.4.0)\n",
      "Installing collected packages: retrying, plotly, catboost\n",
      "Successfully installed catboost-0.22 plotly-4.5.3 retrying-1.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5907034\ttotal: 535ms\tremaining: 53s\n",
      "1:\tlearn: 0.6356107\ttotal: 1.08s\tremaining: 53.2s\n",
      "2:\tlearn: 0.6411256\ttotal: 1.63s\tremaining: 52.7s\n",
      "3:\tlearn: 0.6480344\ttotal: 2.18s\tremaining: 52.4s\n",
      "4:\tlearn: 0.6508222\ttotal: 2.74s\tremaining: 52s\n",
      "5:\tlearn: 0.6499939\ttotal: 3.25s\tremaining: 51s\n",
      "6:\tlearn: 0.6507818\ttotal: 3.77s\tremaining: 50s\n",
      "7:\tlearn: 0.6548422\ttotal: 4.29s\tremaining: 49.4s\n",
      "8:\tlearn: 0.6559533\ttotal: 4.81s\tremaining: 48.7s\n",
      "9:\tlearn: 0.6560947\ttotal: 5.34s\tremaining: 48s\n",
      "10:\tlearn: 0.6568421\ttotal: 5.87s\tremaining: 47.5s\n",
      "11:\tlearn: 0.6588219\ttotal: 6.37s\tremaining: 46.7s\n",
      "12:\tlearn: 0.6592259\ttotal: 6.89s\tremaining: 46.1s\n",
      "13:\tlearn: 0.6611248\ttotal: 7.42s\tremaining: 45.6s\n",
      "14:\tlearn: 0.6625591\ttotal: 7.96s\tremaining: 45.1s\n",
      "15:\tlearn: 0.6631853\ttotal: 8.47s\tremaining: 44.5s\n",
      "16:\tlearn: 0.6639328\ttotal: 9.02s\tremaining: 44s\n",
      "17:\tlearn: 0.6668821\ttotal: 9.54s\tremaining: 43.5s\n",
      "18:\tlearn: 0.6669630\ttotal: 10.1s\tremaining: 42.9s\n",
      "19:\tlearn: 0.6675286\ttotal: 10.6s\tremaining: 42.5s\n",
      "20:\tlearn: 0.6673266\ttotal: 11.2s\tremaining: 42.1s\n",
      "21:\tlearn: 0.6677104\ttotal: 11.8s\tremaining: 41.7s\n",
      "22:\tlearn: 0.6682558\ttotal: 12.3s\tremaining: 41.3s\n",
      "23:\tlearn: 0.6683972\ttotal: 12.9s\tremaining: 40.8s\n",
      "24:\tlearn: 0.6686599\ttotal: 13.4s\tremaining: 40.3s\n",
      "25:\tlearn: 0.6681952\ttotal: 14s\tremaining: 39.8s\n",
      "26:\tlearn: 0.6684982\ttotal: 14.5s\tremaining: 39.3s\n",
      "27:\tlearn: 0.6692053\ttotal: 15.2s\tremaining: 39s\n",
      "28:\tlearn: 0.6696699\ttotal: 15.8s\tremaining: 38.6s\n",
      "29:\tlearn: 0.6699325\ttotal: 16.4s\tremaining: 38.2s\n",
      "30:\tlearn: 0.6705992\ttotal: 17s\tremaining: 37.7s\n",
      "31:\tlearn: 0.6709426\ttotal: 17.5s\tremaining: 37.3s\n",
      "32:\tlearn: 0.6708012\ttotal: 18.1s\tremaining: 36.8s\n",
      "33:\tlearn: 0.6709426\ttotal: 18.7s\tremaining: 36.3s\n",
      "34:\tlearn: 0.6707002\ttotal: 19.3s\tremaining: 35.9s\n",
      "35:\tlearn: 0.6715082\ttotal: 20s\tremaining: 35.5s\n",
      "36:\tlearn: 0.6705992\ttotal: 20.6s\tremaining: 35s\n",
      "37:\tlearn: 0.6725991\ttotal: 21.1s\tremaining: 34.5s\n",
      "38:\tlearn: 0.6729829\ttotal: 21.7s\tremaining: 34s\n",
      "39:\tlearn: 0.6725991\ttotal: 22.3s\tremaining: 33.5s\n",
      "40:\tlearn: 0.6734273\ttotal: 22.9s\tremaining: 33s\n",
      "41:\tlearn: 0.6738314\ttotal: 23.5s\tremaining: 32.5s\n",
      "42:\tlearn: 0.6741546\ttotal: 24.1s\tremaining: 31.9s\n",
      "43:\tlearn: 0.6739728\ttotal: 24.7s\tremaining: 31.4s\n",
      "44:\tlearn: 0.6741950\ttotal: 25.3s\tremaining: 30.9s\n",
      "45:\tlearn: 0.6750636\ttotal: 25.9s\tremaining: 30.4s\n",
      "46:\tlearn: 0.6758919\ttotal: 26.5s\tremaining: 29.9s\n",
      "47:\tlearn: 0.6757707\ttotal: 27.1s\tremaining: 29.4s\n",
      "48:\tlearn: 0.6762151\ttotal: 27.7s\tremaining: 28.9s\n",
      "49:\tlearn: 0.6774474\ttotal: 28.3s\tremaining: 28.3s\n",
      "50:\tlearn: 0.6777100\ttotal: 29s\tremaining: 27.8s\n",
      "51:\tlearn: 0.6786594\ttotal: 29.5s\tremaining: 27.3s\n",
      "52:\tlearn: 0.6789827\ttotal: 30.1s\tremaining: 26.7s\n",
      "53:\tlearn: 0.6804372\ttotal: 30.8s\tremaining: 26.2s\n",
      "54:\tlearn: 0.6804372\ttotal: 31.4s\tremaining: 25.7s\n",
      "55:\tlearn: 0.6809220\ttotal: 32s\tremaining: 25.1s\n",
      "56:\tlearn: 0.6812250\ttotal: 32.6s\tremaining: 24.6s\n",
      "57:\tlearn: 0.6813058\ttotal: 33.2s\tremaining: 24s\n",
      "58:\tlearn: 0.6811846\ttotal: 33.8s\tremaining: 23.5s\n",
      "59:\tlearn: 0.6813260\ttotal: 34.4s\tremaining: 23s\n",
      "60:\tlearn: 0.6816694\ttotal: 35.1s\tremaining: 22.4s\n",
      "61:\tlearn: 0.6823159\ttotal: 35.8s\tremaining: 21.9s\n",
      "62:\tlearn: 0.6832653\ttotal: 36.4s\tremaining: 21.4s\n",
      "63:\tlearn: 0.6840734\ttotal: 37.1s\tremaining: 20.8s\n",
      "64:\tlearn: 0.6840734\ttotal: 37.7s\tremaining: 20.3s\n",
      "65:\tlearn: 0.6846592\ttotal: 38.4s\tremaining: 19.8s\n",
      "66:\tlearn: 0.6843360\ttotal: 39.1s\tremaining: 19.3s\n",
      "67:\tlearn: 0.6846390\ttotal: 39.9s\tremaining: 18.8s\n",
      "68:\tlearn: 0.6854269\ttotal: 40.6s\tremaining: 18.2s\n",
      "69:\tlearn: 0.6858309\ttotal: 41.3s\tremaining: 17.7s\n",
      "70:\tlearn: 0.6858309\ttotal: 41.9s\tremaining: 17.1s\n",
      "71:\tlearn: 0.6865783\ttotal: 42.6s\tremaining: 16.6s\n",
      "72:\tlearn: 0.6864167\ttotal: 43.2s\tremaining: 16s\n",
      "73:\tlearn: 0.6868611\ttotal: 43.9s\tremaining: 15.4s\n",
      "74:\tlearn: 0.6869217\ttotal: 44.5s\tremaining: 14.8s\n",
      "75:\tlearn: 0.6870429\ttotal: 45.2s\tremaining: 14.3s\n",
      "76:\tlearn: 0.6875278\ttotal: 45.9s\tremaining: 13.7s\n",
      "77:\tlearn: 0.6881136\ttotal: 46.6s\tremaining: 13.1s\n",
      "78:\tlearn: 0.6883762\ttotal: 47.3s\tremaining: 12.6s\n",
      "79:\tlearn: 0.6888207\ttotal: 47.9s\tremaining: 12s\n",
      "80:\tlearn: 0.6892449\ttotal: 48.6s\tremaining: 11.4s\n",
      "81:\tlearn: 0.6898509\ttotal: 49.4s\tremaining: 10.8s\n",
      "82:\tlearn: 0.6897095\ttotal: 50.1s\tremaining: 10.3s\n",
      "83:\tlearn: 0.6902549\ttotal: 50.8s\tremaining: 9.67s\n",
      "84:\tlearn: 0.6909822\ttotal: 51.4s\tremaining: 9.07s\n",
      "85:\tlearn: 0.6910832\ttotal: 52.1s\tremaining: 8.48s\n",
      "86:\tlearn: 0.6914468\ttotal: 52.8s\tremaining: 7.89s\n",
      "87:\tlearn: 0.6916084\ttotal: 53.5s\tremaining: 7.29s\n",
      "88:\tlearn: 0.6919922\ttotal: 54.1s\tremaining: 6.69s\n",
      "89:\tlearn: 0.6925579\ttotal: 54.8s\tremaining: 6.09s\n",
      "90:\tlearn: 0.6928407\ttotal: 55.4s\tremaining: 5.48s\n",
      "91:\tlearn: 0.6930427\ttotal: 56s\tremaining: 4.87s\n",
      "92:\tlearn: 0.6935073\ttotal: 56.7s\tremaining: 4.27s\n",
      "93:\tlearn: 0.6940932\ttotal: 57.4s\tremaining: 3.66s\n",
      "94:\tlearn: 0.6944972\ttotal: 58s\tremaining: 3.05s\n",
      "95:\tlearn: 0.6948810\ttotal: 58.6s\tremaining: 2.44s\n",
      "96:\tlearn: 0.6951840\ttotal: 59.5s\tremaining: 1.84s\n",
      "97:\tlearn: 0.6954264\ttotal: 1m\tremaining: 1.23s\n",
      "98:\tlearn: 0.6955881\ttotal: 1m 1s\tremaining: 617ms\n",
      "99:\tlearn: 0.6956285\ttotal: 1m 1s\tremaining: 0us\n",
      "Accuracy: 69.64 %\n",
      "Time: 62.13 seconds\n"
     ]
    }
   ],
   "source": [
    "# !pip install catboost\n",
    "import catboost as cb\n",
    "start = time.time() # 시작 시간 지정\n",
    "cb_dtrain = cb.Pool(data = train_x, label = train_y) # 학습 데이터를 Catboost 모델에 맞게 변환\n",
    "cb_param = {'max_depth': 10, # 트리 깊이\n",
    "            'learning_rate': 0.01, # Step Size\n",
    "            'n_estimators': 100, # Number of trees, 트리 생성 개수\n",
    "            'eval_metric': 'Accuracy', # 평가 척도\n",
    "            'loss_function': 'MultiClass'} # 손실 함수, 목적 함수\n",
    "cb_model = cb.train(pool = cb_dtrain, params = cb_param) # 학습 진행\n",
    "cb_model_predict = np.argmax(cb_model.predict(test_x), axis = 1) + 1 # 평가 데이터 예측, Softmax의 결과값 중 가장 큰 값의 Label로 예측, 인덱스의 순서를 맞추기 위해 +1\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(test_y, cb_model_predict) * 100), \"%\") # 정확도 % 계산\n",
    "print(\"Time: %.2f\" % (time.time() - start), \"seconds\") # 코드 실행 시간 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.34047199,  1.18951783,  0.4296545 , ..., -0.17528062,\n",
       "        -0.02512535, -0.23089952],\n",
       "       [-0.05653916,  0.45365426,  0.17195659, ...,  0.22287606,\n",
       "         0.26190632,  0.18447355],\n",
       "       [-0.31311   , -0.31539546, -0.31876501, ..., -0.29816626,\n",
       "        -0.238871  , -0.3180434 ],\n",
       "       ...,\n",
       "       [ 0.04726952,  0.03794315, -0.17880234, ..., -0.2456077 ,\n",
       "         0.11886516,  1.54034182],\n",
       "       [-0.55746055,  1.77202298,  0.97862619, ..., -0.33775734,\n",
       "        -0.48741853, -0.37792919],\n",
       "       [-0.31665504,  0.08335556, -0.10060578, ...,  0.67896862,\n",
       "         1.03198771, -0.14349506]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict=cb_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  floors  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00     1.0   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25     2.0   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00     1.0   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00     1.0   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00     1.0   \n",
       "\n",
       "   waterfront  condition  grade  yr_built  yr_renovated  zipcode      lat  \\\n",
       "0           0          3      7      1955             0    98178  47.5112   \n",
       "1           0          3      7      1951          1991    98125  47.7210   \n",
       "2           0          3      6      1933             0    98028  47.7379   \n",
       "3           0          5      7      1965             0    98136  47.5208   \n",
       "4           0          3      8      1987             0    98074  47.6168   \n",
       "\n",
       "      long  \n",
       "0 -122.257  \n",
       "1 -122.319  \n",
       "2 -122.233  \n",
       "3 -122.393  \n",
       "4 -122.045  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "data = pd.read_csv(\"./kc_house_data.csv\") \n",
    "data.head() # 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['id', 'date', 'zipcode', 'lat', 'long'], axis = 1) # id, date, zipcode, lat, long  제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15129, 8) (6484, 8) (15129,) (6484,)\n"
     ]
    }
   ],
   "source": [
    "feature_columns = list(data.columns.difference(['price'])) # Price를 제외한 모든 행\n",
    "X = data[feature_columns]\n",
    "y = data['price']\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 42) # 학습데이터와 평가데이터의 비율을 7:3\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape) # 데이터 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhyun\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "# !pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "start = time.time() # 시작 시간 지정\n",
    "lgb_dtrain = lgb.Dataset(data = train_x, label = train_y) # 학습 데이터를 LightGBM 모델에 맞게 변환\n",
    "lgb_param = {'max_depth': 10, # 트리 깊이\n",
    "            'learning_rate': 0.01, # Step Size\n",
    "            'n_estimators': 500, # Number of trees, 트리 생성 개수\n",
    "            'objective': 'regression'} # 파라미터 추가, Label must be in [0, num_class) -> num_class보다 1 커야한다.\n",
    "lgb_model = lgb.train(params = lgb_param, train_set = lgb_dtrain) # 학습 진행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210904.17249451784"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "sqrt(mean_squared_error(lgb_model.predict(test_x),test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 239833.03198683602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regression_model = LinearRegression() # 선형 회귀 모형\n",
    "bagging_model = BaggingRegressor(base_estimator = regression_model, # 선형회귀모형\n",
    "                                 n_estimators = 10, # 10번 샘플링\n",
    "                                 verbose = 1) # 학습 과정 표시\n",
    "linear_model2 = bagging_model.fit(train_x, train_y) # 학습 진행\n",
    "predict2 = linear_model2.predict(test_x) # 학습된 Bagging 선형 회귀 모형으로 평가 데이터 예측\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(predict2, test_y)))) # RMSE 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 239833.03198683602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "decision_tree=DecisionTreeRegressor()\n",
    "bagging_model2=BaggingRegressor(base_estimator=decision_tree,\n",
    "                               n_estimators=10,\n",
    "                               verbose=1)\n",
    "decision_model=bagging_model2.fit(train_x,train_y)\n",
    "decision_predict=decision_model.predict(test_x)\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(predict2, test_y)))) # RMSE 결과"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
